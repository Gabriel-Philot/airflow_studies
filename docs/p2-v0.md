# V0


Ref:

#### [Link __airflow-docs__  ](https://airflow.apache.org/docs/)
#### [Link __docker-docs__  ](https://docs.docker.com/reference/cli/docker/container/run/)
#### [ My own Docker-studies repo ](https://github.com/Gabriel-Philot/docker_studies)
#### [Friend repo's refence for starting out (bAlemar Bernardo Alemar)](https://github.com/bAlemar/WebScraping-AirFlow/blob/main/V2/README.md)
#### [youtube airflow ref video](https://www.youtube.com/watch?v=w8Z--fpEpyU)
#### [dev good habits ref video (luhborba Luciano Borba)](https://www.youtube.com/watch?v=h_tir_Lfx8M)
#### [youtube airflow ref video (pass data betweenn tasks)](https://www.youtube.com/watch?v=WLXLU63WXTg)


## First Steps to starting airflow_extended image and some dags exemple.

Here our goal wil be to make some easy dags to get started.
One thing prob's diferent then other first step guides, its that this v0 starts with the use of imported functions from dag 0 to beyond.

* First thing after get all the requirements installed its to Dockerfile & docker-compose.yaml

> [!Note]
> The project's organization will affect the interaction between these two files.

### Important points to be awere here:

*In docker-compose.file*:

(1) look for the image part of the aiflow: `image: ${AIRFLOW_IMAGE_NAME:-{image name}:{image tag}}`

e.g.: `image: ${AIRFLOW_IMAGE_NAME:-extening_v0_airflow_image:1.0.0}`

this image name and image tag wil be used in the docker build command.

(2) in volumes add your src folder, to get autoreload of your modules.

```
volumes:
    ....
    ....
    ....
    - ./src:/usr/local/airflow/src # (!!!!)
```

(3) [Optional] here turn off the tons of example dags that floods our vision.
`AIRFLOW__CORE__LOAD_EXAMPLES: 'false`

### Intructions to build and run the airflow-docker image:

*(1) Build the Dockerfile (extended image):*


`docker build -t {image name}:{image tag}`  __SAME AS IN docker-compose.file__

*(2) Giving linux some variables definitions:*


`echo -e "AIRFLOW_UID=$(id -u)\nAIRFLOW_GID=0" > .env `

*(3) Run the docker-compose first start for airflow*


`docker-compose up airflow-init`

Here dont worry, after this its done problably you will see your airflow-container going down by him self.
```
airflow-init_1       |airflow already exist in the db
airflow-init_1       | 2.8.2
v0_airflow-init_1 exited with code 0
```
Don't worry, these are normal checks to see if the database is already created.

*(4) Normal docker-compose up to start the airflow and start the game*



`docker-compose up`


### Airflow-web: http://localhost:8080/

* username: airflow
* password: airflow


## DAGS:

### *First dag: dag_import_test.py*
This dag its just a test to see if we can import modules from other files.
it uses two functions.

::: v0.src.resources.test_module.get_requests
::: v0.src.resources.test_module.get_beatiful
(Just two functions that basically print a library.)

### *Second dag: dag_refresh_test.py*
This dag its just a test to see if the modules can be update without the need to restart the container.

### *Third: dag_spotify_test.py*
This dag its a short adapitation of one docker studie that i done, my goal was to test out the extraction and process functions in airflow.

::: v0.src.main.extract_api

::: v0.src.main.transform_api

so basically its a excract, load and print dag for testing airflow+docker working togetter.


## LIST OF OTHERS USEFUL DOCKER-COMMANDS HERE:
```
docker-compose down
docker ps
docker ps -a
docker images
docker image rm {image.name (or id)}:{image.tag} # Correct way to erase your images
docker rmi $(docker images -q) # ERASES ALL THE IMAGES !!! NOT RECOMMENDED TO USE NEAR PROD SYSTEMS
```



